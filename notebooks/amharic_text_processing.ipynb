{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Processing: Handling Amharic text, tokenization, and preprocessing techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To preprocess the scraped Amharic text data for tasks like tokenization, normalization, and handling Amharic-specific linguistic features, we need to follow several preprocessing steps tailored for the language. \n",
    "\n",
    "Here‚Äôs how we can approach this task:\n",
    "\n",
    "**Steps to Preprocess Amharic Text**\n",
    "\n",
    "- **Tokenization**: Tokenization is the process of splitting text into individual units such as words or subwords. Since Amharic uses a different script and has some unique linguistic features, tokenizing might need adjustments. \n",
    "    - Use specialized libraries that handle Amharic text or a custom rule-based tokenizer.\n",
    "\n",
    "- **Normalization**: This step involves cleaning and converting the text into a standard format:\n",
    "\n",
    "    - Remove special characters, punctuation, and numbers.\n",
    "    - Normalize similar-looking characters.\n",
    "    - Convert text to a standard form (for example, removing diacritics if necessary).\n",
    "\n",
    "- **Handling Amharic-Specific Features:**\n",
    "\n",
    "    - Amharic, like other Semitic languages, has specific features such as root-and-pattern morphology.\n",
    "\n",
    "    - Handling unique orthographic variants and considering suffixes, prefixes, and infixes in the language.\n",
    "\n",
    "    - Identifying verb conjugations, plural forms, and possessives for better tokenization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-25 15:46:50,870 - INFO - Imported libraries and configured logging.\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import logging\n",
    "import os, sys\n",
    "# Add the 'scripts' directory to the Python path for module imports\n",
    "sys.path.append(os.path.abspath(os.path.join('..', 'scripts')))\n",
    "# Import data preprocessor class\n",
    "from amharic_text_processor import AmharicTextPreprocessor\n",
    "\n",
    "# Set max rows and columns to display\n",
    "pd.set_option('display.max_columns', 200)\n",
    "pd.set_option('display.max_rows', 200)\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, \n",
    "                    format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "logger.info(\"Imported libraries and configured logging.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load the scraped Telegram data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Channel Title</th>\n",
       "      <th>Channel Username</th>\n",
       "      <th>ID</th>\n",
       "      <th>Message</th>\n",
       "      <th>Date</th>\n",
       "      <th>Media Path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>·àç·ã© ·ä•·âÉ</td>\n",
       "      <td>@Leyueqa</td>\n",
       "      <td>5819</td>\n",
       "      <td>üî†üî†üî†üî†üî†Siliver crest ‚û°Ô∏èBrand¬† ·â£·àà1 ·ä•·äì ·â£·àà¬† 2 ·â∞·âΩ ·àµ·â∂...</td>\n",
       "      <td>2024-09-25 17:39:49+00:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>·àç·ã© ·ä•·âÉ</td>\n",
       "      <td>@Leyueqa</td>\n",
       "      <td>5818</td>\n",
       "      <td>üî†üî†üî†üî†·à∂·àµ·âµ ·çç·à¨ ·ã®·ã≥·â¶ ·ä•·äì ·ã®·ä¨·ä≠ ·âÖ·à≠·åΩ ·àõ·ãç·å´ ( ·àò·åã·åà·à™·ã´ ·çì·âµ·à´ )\\n\\...</td>\n",
       "      <td>2024-09-25 10:38:58+00:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>·àç·ã© ·ä•·âÉ</td>\n",
       "      <td>@Leyueqa</td>\n",
       "      <td>5817</td>\n",
       "      <td>üß≥üß≥üß≥HIGH PRESSURE WATER GUN HEAD SET\\nüëâ 360¬∞ ·ã®·àö...</td>\n",
       "      <td>2024-09-25 07:44:47+00:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>·àç·ã© ·ä•·âÉ</td>\n",
       "      <td>@Leyueqa</td>\n",
       "      <td>5816</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-09-25 05:48:40+00:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>·àç·ã© ·ä•·âÉ</td>\n",
       "      <td>@Leyueqa</td>\n",
       "      <td>5815</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-09-25 05:48:40+00:00</td>\n",
       "      <td>../data/photos/@Leyueqa_5815.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Channel Title Channel Username    ID  \\\n",
       "0         ·àç·ã© ·ä•·âÉ         @Leyueqa  5819   \n",
       "1         ·àç·ã© ·ä•·âÉ         @Leyueqa  5818   \n",
       "2         ·àç·ã© ·ä•·âÉ         @Leyueqa  5817   \n",
       "3         ·àç·ã© ·ä•·âÉ         @Leyueqa  5816   \n",
       "4         ·àç·ã© ·ä•·âÉ         @Leyueqa  5815   \n",
       "\n",
       "                                             Message  \\\n",
       "0  üî†üî†üî†üî†üî†Siliver crest ‚û°Ô∏èBrand¬† ·â£·àà1 ·ä•·äì ·â£·àà¬† 2 ·â∞·âΩ ·àµ·â∂...   \n",
       "1  üî†üî†üî†üî†·à∂·àµ·âµ ·çç·à¨ ·ã®·ã≥·â¶ ·ä•·äì ·ã®·ä¨·ä≠ ·âÖ·à≠·åΩ ·àõ·ãç·å´ ( ·àò·åã·åà·à™·ã´ ·çì·âµ·à´ )\\n\\...   \n",
       "2  üß≥üß≥üß≥HIGH PRESSURE WATER GUN HEAD SET\\nüëâ 360¬∞ ·ã®·àö...   \n",
       "3                                                NaN   \n",
       "4                                                NaN   \n",
       "\n",
       "                        Date                        Media Path  \n",
       "0  2024-09-25 17:39:49+00:00                               NaN  \n",
       "1  2024-09-25 10:38:58+00:00                               NaN  \n",
       "2  2024-09-25 07:44:47+00:00                               NaN  \n",
       "3  2024-09-25 05:48:40+00:00                               NaN  \n",
       "4  2024-09-25 05:48:40+00:00  ../data/photos/@Leyueqa_5815.jpg  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the data\n",
    "data = pd.read_csv('../data/telegram_data.csv')\n",
    "# Explore the first five rows\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Channel Title</th>\n",
       "      <th>Channel Username</th>\n",
       "      <th>ID</th>\n",
       "      <th>Message</th>\n",
       "      <th>Date</th>\n",
       "      <th>Media Path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1666</th>\n",
       "      <td>·àç·ã© ·ä•·âÉ</td>\n",
       "      <td>@Leyueqa</td>\n",
       "      <td>148</td>\n",
       "      <td>·ã≠·àò·âª·âπ ·çà·â≥ ·ã´·àà ·àù·àΩ·âµ ·â∞·àò·äò·àÅ</td>\n",
       "      <td>2018-10-25 13:09:24+00:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1667</th>\n",
       "      <td>·àç·ã© ·ä•·âÉ</td>\n",
       "      <td>@Leyueqa</td>\n",
       "      <td>136</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-10-20 12:46:15+00:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1668</th>\n",
       "      <td>·àç·ã© ·ä•·âÉ</td>\n",
       "      <td>@Leyueqa</td>\n",
       "      <td>70</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-09-04 15:28:25+00:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1669</th>\n",
       "      <td>·àç·ã© ·ä•·âÉ</td>\n",
       "      <td>@Leyueqa</td>\n",
       "      <td>55</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-08-23 20:18:56+00:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1670</th>\n",
       "      <td>·àç·ã© ·ä•·âÉ</td>\n",
       "      <td>@Leyueqa</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-08-02 07:30:19+00:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Channel Title Channel Username   ID              Message  \\\n",
       "1666         ·àç·ã© ·ä•·âÉ         @Leyueqa  148  ·ã≠·àò·âª·âπ ·çà·â≥ ·ã´·àà ·àù·àΩ·âµ ·â∞·àò·äò·àÅ   \n",
       "1667         ·àç·ã© ·ä•·âÉ         @Leyueqa  136                  NaN   \n",
       "1668         ·àç·ã© ·ä•·âÉ         @Leyueqa   70                  NaN   \n",
       "1669         ·àç·ã© ·ä•·âÉ         @Leyueqa   55                  NaN   \n",
       "1670         ·àç·ã© ·ä•·âÉ         @Leyueqa    1                  NaN   \n",
       "\n",
       "                           Date Media Path  \n",
       "1666  2018-10-25 13:09:24+00:00        NaN  \n",
       "1667  2018-10-20 12:46:15+00:00        NaN  \n",
       "1668  2018-09-04 15:28:25+00:00        NaN  \n",
       "1669  2018-08-23 20:18:56+00:00        NaN  \n",
       "1670  2018-08-02 07:30:19+00:00        NaN  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the last five rows\n",
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Channel Title         0\n",
       "Channel Username      0\n",
       "ID                    0\n",
       "Message             704\n",
       "Date                  0\n",
       "Media Path          546\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's check the missing values\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized Amharic Text: ['·à∞·àã·àù', '·ä•·äï·ã¥·âµ', '·äê·àÖ', '?', '·ä•·äï·ä≥·äï', '·ã∞·àÖ·äì', '·àò·å£·àÖ']\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Amharic text sample\n",
    "    amharic_text = \"·à∞·àã·àù ·ä•·äï·ã¥·âµ ·äê·àÖ? ·ä•·äï·ä≥·äï ·ã∞·àÖ·äì ·àò·å£·àÖ·ç¢\"\n",
    "\n",
    "    preprocessor = AmharicTextPreprocessor()\n",
    "\n",
    "    # Preprocess the text\n",
    "    tokens = preprocessor.preprocess(amharic_text)\n",
    "    print(\"Tokenized Amharic Text:\", tokens)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
